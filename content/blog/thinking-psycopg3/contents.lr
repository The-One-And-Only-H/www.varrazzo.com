title: Thinking psycopg3
---
pub_date: 2020-03-06
---
author: Daniele Varrazzo
---
image: /img/blog/disks.jpg
---
_discoverable: yes
---
tags:

software
design
psycopg
---
body:

I have been psycopg2_ maintainer since 2010; before that, `git says`__ that my
first contribution was in 2005. At that time, psycopg (one) was the tool to
use, and psycopg2 was an interesting experiment.

.. _psycopg2: https://www.psycopg.org/
.. __: https://github.com/psycopg/psycopg2/commit/4805a935690b1d618247267318a0ef7aa06c2378

In several years of using psycopg2 daily and reading about expectations,
frustrations, surprises experienced by other users, I have been making my mind
about a better system, and if I had to release a version incompatible with the
past, those are some of the things I would change.


Query parameters adaptation
===========================

psycopg2 composes queries (replacing the placeholders in the SQL strings with
the values supplied by the user) on the client, and sends a complete query to
the server.

.. image:: seq-psycopg2.jpg
    :alt: Sequence diagram for psycopg2
    :class: mb10 align-center

It does its job right, so it doesn't result in SQL injection vulnerabilities.
However the correct way of doing it, as far as PostgreSQL is concerned, should
be to send the query and its parameters separately (i.e. using the
|PQexecParams|_ libpq function rather than |PQexec|_).

.. image:: seq-psycopg3.jpg
    :alt: Sequence diagram for psycopg3
    :class: mb10 align-center

Separating the statement from the parameters improves performance and memory
usage at parsing time. However the behaviour of the library would change
slightly, which is the reason why server-side merging hasn't been used so far.
For instance:

- |PQexecParams| only supports one command at time: it wouldn't be possible
  anymore to send a batch of queries separated by semicolon in a single
  ``execute()`` call.

- psycopg2 helps solving some type casting ambiguities by attaching casts to
  the types represented as strings (e.g. the date 1/1/2020 is currently merged
  to the query as ``'2010-01-01'::date``); using |PQexecParams| the trick
  wouldn't be available anymore. It might be possible maybe to suggest the
  type in other ways, but if that's not the case then queries should be
  modified by applying explicit casts next to their placeholders (e.g.
  ``%s::date``).

- Custom-defined adapters should be rewritten.

.. |PQexec| replace:: ``PQexec``
.. _PQexec: https://www.postgresql.org/docs/current/libpq-exec.html#LIBPQ-PQEXEC
.. |PQexecParams| replace:: ``PQexecParams``
.. _PQexecParams: https://www.postgresql.org/docs/current/libpq-exec.html#LIBPQ-PQEXECPARAMS

The main difference between the old adaptation protocol (called |ISQLQuote|_)
and the new one (which doesn't have a name yet, it could be probably called
``ISQL``) is the use of the quotes, whereby the string ``O'Connor`` is passed
to the query as ``'O''Connor'``, with wrapping quotes and doubled-up quotes in
the content. In ``ISQL`` the string wouldn't undergo the same transformation
to add and escape quotes; other types would only have to be converted into
strings in the PostgreSQL syntax, but wouldn't need to be wrapped in quotes to
create a SQL literal. Using ``ISQL`` as the fundamental adaptation steps there
would be some interesting improvements:

- adapting composite types and arrays would be a much more straightforward
  matter,
- it opens the door to the use of `prepared statements`__, but especially
- the ``COPY FROM`` operation could take an iterable object yielding Python
  types instead of a file-like object to read; similarly ``COPY TO`` could
  return an iterable object yielding Python types.

.. __: https://www.postgresql.org/docs/current/libpq-exec.html#LIBPQ-PQPREPARE

I mean: this would be great! |COPY|_ is by far the most efficient way to
insert data into the database: using it via psycopg2 requires exposing the
data via a `file-like object`__, which not only is a weird interface, but it
requires people to roll their own adaptation format. The target for copying
data into the database using psycopg3 should be as easy as:

.. code:: python

    curs.copy("COPY song (artist, title) FROM STDIN", [
        ("Sinead O'Connor", "Nothing Compares 2 U"),
        ('REM', "Losing my Religion"),
    ])

.. |ISQLQuote| replace:: ``ISQLQuote``
.. _ISQLQuote: https://www.psycopg.org/docs/extensions.html#psycopg2.extensions.ISQLQuote
.. |COPY| replace:: ``COPY``
.. _COPY: https://www.postgresql.org/docs/current/sql-copy.html
.. __: https://www.psycopg.org/docs/usage.html#using-copy-to-and-copy-from


Context managers and transactions
=================================

psycopg2 follows a de-facto standard (which was `widely discussed`__ but which
never landed in the `DBAPI specs`__), whereby connections used as context
managers wrap a transaction, committing it if exiting on success or rolling it
back in case of error. So the way to use it is something like:

.. code:: python

    conn = connect(DSN)
    try:
        # these are two separate transactions
        with conn:
            do_something(conn)
        with conn:
            do_something_else(conn)

.. __: https://mail.python.org/pipermail/db-sig/2012-November/thread.html
.. __: https://www.python.org/dev/peps/pep-0249/

This idea has its usefulness,  but it is a *very* surprising behaviour:
developers usually expect the same resources released by ``close()`` to be
released on context exit (as files, sockets, and even DBAPI cursors do). It
also gets in the way of managing different life cycles on the connection, for
instance if there is the connection is taken from a pool:

.. code:: python

    with pool.getconn() as conn:
        with conn.cursor() as curs:
            do_someting(curs)

then it is expected (and `reasonably requested`__) that the connection is
returned to the pool at the end of the block.

Talking about transactions, PostgreSQL support for ``SAVEPOINT`` makes
possible to implement nested transactions (already implemented on top of
psycopg2 e.g. `by Django`__ and `in a stand-alone module`__). This seems to
ask for a different context than the connection-scope one. So maybe it would
be useful to leave the latter to the management of the resource, releasing
them on connection context exit, and to add an explicit method to start an
atomic block (either a transaction or a savepoint, according to the current
connection state):

.. __: https://github.com/psycopg/psycopg2/pull/17
.. __: https://docs.djangoproject.com/en/3.0/topics/db/transactions/#django.db.transaction.atomic
.. __: https://github.com/asqui/psycopg-nestedtransactions

.. code:: python

    with connect(DSN) as conn:
        with conn.transaction():
            do_something()
            with conn.transaction():
                do_something_nested()

        with conn.transaction() as tx:
            do_something_else()
            # we were just testing and we don't really want to do this
            tx.rollback()

    # and here the connection is closed


Optional C module
=================

psycopg2 is a C extension module wrapping the libpq_, the PostgreSQL client
library. As such, in order to build, it requires a C compiler, Python, and
libpq development packages. It is a relatively low bar, but it can be a pain
nonetheless for beginner users.

We tried to avoid the problem by shipping a `wheel package`_, but the
experience has been `far from being a success`__,  marred by diverse issues
such as the possible incompatibility between the libcrypto used by Python and
by the libpq, the lack of support for musl libc/Alpine Linux (much in demand
in Docker images), broken assumptions (like `glibc breaking backwards
compatibility`__)... There's just too much magic needed to work smoothly.

.. _wheel package: https://pythonwheels.com/
.. __: https://github.com/psycopg/psycopg2/issues?utf8=%E2%9C%93&q=+label%3Awheel
.. __: https://github.com/pypa/manylinux/issues/305

.. _libpq: https://www.postgresql.org/docs/current/libpq.html

In the past years, mostly in order to support PyPy_, a few "python-only"
psycopg2 implementations have been developed: first a `ctypes
implementation`__, to which I contributed but which hasn't been maintained at
the same feature level of the reference C psycopg2. This package was further
forked into a `cffi implementation`__, which seems to be more active, but
whose release numbers don't follow the original ones, which is mighty
confusing.

.. _PyPy: https://www.pypy.org/
.. __: https://github.com/mvantellingen/psycopg2-ctypes
.. __: https://github.com/chtd/psycopg2cffi

psycopg3 might follow an approach I've seen used in other extension modules
such as PyYAML, which try to compile an optimized version of the library and
fall back to a Python implementation if that fails. Using the C module over
the Python module would be a preference at import time, but if could still be
possible to enforce the use of one specific implementation, for instance using
a ``PSYCOPG3_IMPL={C|PYTHON}`` environment variable, which would make the lack
of the requested implementation an import time error.


Async from the ground up
========================

The DBAPI interface is synchronous and blocking by design: ``connect()``
blocks until a connection is open, ``execute()`` blocks until the query is
completed etc. This didn't stop psycopg2 to work asynchronously, exposing two
different interfaces for it:

- `a purely asynchronous one`__ where the application must explicitly
  ``poll()`` to bring forward the connection/execution process: it breaks the
  DBAPI interface but allows frameworks who can't make blocking calls anyway
  (such as the revered Twisted_) to use it;
- `a coroutine-based one`__ where the DBAPI blocking interface is respected
  but behind the scene psycopg2 collaborates with coroutine libraries such as
  Eventlet_ and gevent_.

.. __: https://www.psycopg.org/docs/advanced.html#asynchronous-support
.. __: https://www.psycopg.org/docs/advanced.html#support-for-coroutine-libraries
.. _Twisted: https://twistedmatrix.com/
.. _Eventlet: https://eventlet.net/
.. _gevent: http://www.gevent.org/
.. _aiohttp: https://aiohttp.readthedocs.io/

Needless to say, the world has gone forward, and Python now offers core
support in its syntax and library to asyncio_: this is the foundation that
newer Python async frameworks, such as aiohttp_, are built upon. A third-part
wrapper, aiopg_, currently helps to bridge the async mode of psycopg2 with the
asyncio machinery, but of course there is some overhead, mostly caused by the
fact that the C implementation of psycopg2 is a relatively thick layer, with
the libpq async calls deeply buried under the C implementation of the Python
``connection`` and ``cursor`` objects and behind their interfaces.

There is a chance now to rethink how thick the C libpq wrapper should be. We
can reduce the C implementation to a minimal wrapper around the libpq
(replaceable by a CFFI Python wrapper if compiling C is not available on the
client), using it as a foundation to build a familiar DBAPI blocking
interface. A blocking behaviour is not bad in itself: it allows to write most
of the programs, the ones which don't need crazy concurrency, in a simple and
familiar paradigm; the async layer would be available under the hood to
squeeze the best performance in programs who have embraced an asynchronous
pattern and framework. Time for a picture:

.. image:: architecture.jpg
    :alt: Proposed architecture for psycopg3
    :class: mb10 align-center

.. _asyncio: https://docs.python.org/3.8/library/asyncio.html
.. _aiopg: https://github.com/aio-libs/aiopg


Other improvements
==================

I've written down some of the ideas to implement on `a Trello board`__ and in
`an issues milestone`__. As the board shows, some of the improvements weren't
actually incompatible with psycopg2 and over the years they have already
landed in in its releases; some other ones will have to wait.

.. __: https://trello.com/b/6tF2oHJ0/psycopg3
.. __: https://github.com/psycopg/psycopg2/milestone/4

Some of what could be improved over psycopg2:

- async COPY methods (see `issue #428`_);
- better support for SQL_ASCII databases (which, unlike what their name
  suggests, are actually unencoded 8 bits, see `issue #519`_);
- `preparing cursors`_;
- return value on ``execute()``:

  .. code:: python

    for record in cur.execute(query):
        # ...

- connection and cursor-scoped adapters (currently you can scope the
  adaptation rules from Postgres to Python but the rules from Python to
  Postgres can only be global);
- reorganising the extensions_ and extras_ module, which at the moment contain
  an heterogeneous assortment of objects, functions, constants...

.. _issue #428: https://github.com/psycopg/psycopg2/issues/428
.. _issue #519: https://github.com/psycopg/psycopg2/issues/519
.. _preparing cursors: https://gist.github.com/dvarrazzo/3797445
.. _extensions: https://www.psycopg.org/docs/extensions.html
.. _extras: https://www.psycopg.org/docs/extras.html

I would be interested in starting the development of this project soon. If you
have opinions, or interest in the project, please let us know on the `Mailing
List`_ (you can `subscribe here`__).

.. __: https://lists.postgresql.org/
.. _mailing list: https://www.postgresql.org/list/psycopg/

...and if psycopg2 has been useful so far for you and for your business and if
you would love to see a psycopg3 even more performing and easier to use,
please consider `sponsoring the development`__, thank you! 💜

.. __: https://github.com/sponsors/dvarrazzo/
